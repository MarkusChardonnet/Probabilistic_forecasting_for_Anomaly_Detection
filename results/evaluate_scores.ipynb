{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to evaluate inferred microbial anomaly scores\n",
    "\n",
    "To run this notebook you need to create and activate the following conda environment:\n",
    "\n",
    "```\n",
    "conda create --name score_eval numpy pandas matplotlib seaborn scipy ipython ipykernel -y\n",
    "conda activate score_eval\n",
    "pip install -e .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils_eval_score import (\n",
    "    _get_all_scores,\n",
    "    _plot_score_over_age,\n",
    "    _get_abx_info,\n",
    "    _select_samples_around_nth_abx_exposure,\n",
    "    _plot_score_after_nth_abx_exposure,\n",
    "    display_scatterplot_w_scores,\n",
    "    plot_trajectory,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# avg. number of days per month\n",
    "DAYS_PER_MONTH = 30.437"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER input: define the inferred model and linked datasets to evaluate here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT START\n",
    "# name of the model\n",
    "model_name = \"saved_models_microbial_novel_alpha_div/id-2_test\"\n",
    "# which model version to evaluate: \"best\" or \"last\"\n",
    "point_to_evaluate = \"best\"\n",
    "\n",
    "# name of feature dataset used for model\n",
    "ft_name = \"ft_vat19_anomaly_v20240806_entero_family\"\n",
    "# name of abx time-series used for model\n",
    "abx_ts_name = \"ts_vat19_abx_v20240806\"\n",
    "\n",
    "# limit evaluation to time range up to this many months (if None no limit is set\n",
    "# and all scores are evaluated)\n",
    "limit_months = 24.0\n",
    "\n",
    "# whether to group samples prior to abx exposure in analysis\n",
    "group_samples = False\n",
    "\n",
    "# how many samples prior and after abx exposure to consider\n",
    "min_samples = -3.0\n",
    "max_samples = 12.0\n",
    "#### USER INPUT END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_path = f\"../data/{model_name}/anomaly_detection/scores_{point_to_evaluate}/\"\n",
    "evaluation_path = (\n",
    "    f\"../data/{model_name}/anomaly_detection/evaluation_{point_to_evaluate}_overall/\"\n",
    ")\n",
    "\n",
    "if not os.path.exists(evaluation_path):\n",
    "    os.makedirs(evaluation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"both\"\n",
    "\n",
    "# get train\n",
    "scores_train = _get_all_scores(scores_path, \"train\", limit_months=limit_months)\n",
    "\n",
    "# get val\n",
    "scores_val = _get_all_scores(scores_path, \"val\", limit_months=limit_months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get noabx samples per split\n",
    "noabx_train = scores_train[~scores_train[\"abx\"]].copy()\n",
    "noabx_val = scores_val[~scores_val[\"abx\"]].copy()\n",
    "\n",
    "# select correct scores\n",
    "noabx_train.drop(columns=[\"score_2\", \"score_3\"], inplace=True)\n",
    "\n",
    "noabx_val.drop(columns=[\"score_2\", \"score_3\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all abx scores into one group: train + val\n",
    "# since none of the abx samples were used for training\n",
    "abx_scores_flat = scores_train[scores_train[\"abx\"]].copy()\n",
    "abx_scores_flat_val = scores_val[scores_val[\"abx\"]].copy()\n",
    "\n",
    "abx_scores_flat = pd.concat([abx_scores_flat, abx_scores_flat_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add metadata matching samples over time from ft\n",
    "ft_df = pd.read_csv(f\"../data/original_data/{ft_name}.tsv\", sep=\"\\t\", index_col=0)\n",
    "ft_df[\"age_days\"] = ft_df[\"age_days\"].astype(int)\n",
    "ft_df.rename(columns={\"age_days\": \"day\"}, inplace=True)\n",
    "\n",
    "cols_to_evaluate = [\n",
    "    \"abx_any_cumcount\",\n",
    "    \"abx_max_count_ever\",\n",
    "    \"abx_any_last_t_dmonths\",\n",
    "    \"abx_any_last_dur_days\",\n",
    "    \"geo_location_name\",\n",
    "]\n",
    "ft_df = ft_df[[\"day\", \"host_id\"] + cols_to_evaluate].copy()\n",
    "ft_df = ft_df.assign(\n",
    "    max_abx_w_microbiome=lambda df: df.groupby(\"host_id\")[\"abx_any_cumcount\"].transform(\n",
    "        \"max\"\n",
    "    ),\n",
    ")\n",
    "# add additional information to inferred scores\n",
    "print(abx_scores_flat.shape)\n",
    "abx_scores_flat = abx_scores_flat.merge(ft_df, on=[\"host_id\", \"day\"], how=\"left\")\n",
    "print(abx_scores_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after abx exposure 1st, 2nd and 3rd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_abx_ts = f\"../data/original_data/{abx_ts_name}.tsv\"\n",
    "abx_df = _get_abx_info(path_to_abx_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get samples around n-th abx exposure\n",
    "for n in [1, 2, 3]:\n",
    "    score_col = f\"score_{n}\"\n",
    "    scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "        abx_scores_flat,\n",
    "        abx_df,\n",
    "        n=n,\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        group_samples=group_samples,\n",
    "        score_var=score_col,\n",
    "    )\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=score_col,\n",
    "        n=n,\n",
    "        path_to_save=evaluation_path,\n",
    "        flag=split,\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg. time from 1st to 2nd abx exposure:\n",
    "def plot_time_between_abx_exposures(n0, n1, abx_df, n0_label=\"1st\", n1_label=\"2nd\"):\n",
    "    # indexing starts at zero\n",
    "    n0 = n0 -1\n",
    "    n1 = n1 -1\n",
    "    # calculate age at 1st abx exposure for all hosts\n",
    "    abx_age_n0 = abx_df.groupby(\"host_id\").nth(n0)\n",
    "    new_col_n0 = f\"age_{n0_label}_abx\"\n",
    "    abx_age_n0 = abx_age_n0.rename(columns={\"abx_start_age_months\": new_col_n0})\n",
    "    abx_age_n0 = abx_age_n0[[\"host_id\", new_col_n0]].copy()\n",
    "    # calculate age at 2nd\n",
    "    abx_age_n1 = abx_df.groupby(\"host_id\").nth(n1)\n",
    "    new_col_n1 = f\"age_{n1_label}_abx\"\n",
    "    abx_age_n1 = abx_age_n1.rename(columns={\"abx_start_age_months\": new_col_n1})\n",
    "    abx_age_n1 = abx_age_n1[[\"host_id\", new_col_n1]].copy()\n",
    "    # add this column to all_samples\n",
    "    both_age = pd.merge(abx_age_n0, abx_age_n1, on=\"host_id\", how=\"left\")\n",
    "    both_age[\"diff_age\"] = both_age[new_col_n1] - both_age[new_col_n0]\n",
    "    fig, ax = plt.subplots(dpi=400, figsize=(4, 5))\n",
    "    both_age[[\"diff_age\"]].boxplot(ax=ax)\n",
    "    ax.set_title(f\"Time between {n0_label} and {n1_label} abx exposure\")\n",
    "\n",
    "plot_time_between_abx_exposures(1, 2, abx_df, n0_label=\"1st\", n1_label=\"2nd\")\n",
    "plt.show()\n",
    "plot_time_between_abx_exposures(2, 3, abx_df, n0_label=\"2nd\", n1_label=\"3rd\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 1st abx: split by duration: < 7 days vs. >= 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "score_col = f\"score_{n}\"\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "    abx_scores_flat,\n",
    "    abx_df,\n",
    "    n=n,\n",
    "    min_samples=min_samples,\n",
    "    max_samples=max_samples,\n",
    "    group_samples=group_samples,\n",
    "    score_var=score_col,\n",
    ")\n",
    "\n",
    "# bin duration into short, mid and long duration\n",
    "scores_abx_nth_samples[\"abx_any_last_dur_days\"].hist(bins=10)\n",
    "\n",
    "bins = [-float(\"inf\"), 6, float(\"inf\")]\n",
    "dur_labels = [\"< 6 days\", \">= 6 days\"]\n",
    "scores_abx_nth_samples[\"abx_duration_category\"] = pd.cut(\n",
    "    scores_abx_nth_samples[\"abx_any_last_dur_days\"],\n",
    "    bins=bins,\n",
    "    labels=dur_labels,\n",
    "    right=False,\n",
    ")\n",
    "\n",
    "scores_abx_nth_samples[\"abx_duration_category\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for dur in dur_labels:\n",
    "    print(dur)\n",
    "    # evaluation_path_bin = f\"{evaluation_path}duration_bins{i}/\"\n",
    "    host_w_dur = (\n",
    "        scores_abx_nth_samples.loc[\n",
    "            scores_abx_nth_samples[\"abx_duration_category\"] == dur, \"host_id\"\n",
    "        ]\n",
    "        .unique()\n",
    "        .tolist()\n",
    "    )\n",
    "    scores_abx_nth_samples_dur = scores_abx_nth_samples.loc[\n",
    "        scores_abx_nth_samples[\"host_id\"].isin(host_w_dur)\n",
    "    ].copy()\n",
    "\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_dur,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=score_col,\n",
    "        n=n,\n",
    "        path_to_save=None,\n",
    "        flag=split,\n",
    "        tag=f\"duration: {dur}\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples,\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 1st abx: split by time of life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "score_col = f\"score_{n}\"\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "    abx_scores_flat,\n",
    "    abx_df,\n",
    "    n=n,\n",
    "    min_samples=min_samples,\n",
    "    max_samples=max_samples,\n",
    "    group_samples=group_samples,\n",
    "    score_var=score_col,\n",
    ")\n",
    "\n",
    "# bin duration into short, mid and long duration\n",
    "scores_abx_nth_samples[\"age_nth_abx\"].hist(bins=24)\n",
    "\n",
    "bins_age = [-float(\"inf\"), 6, 12, 18, float(\"inf\")]\n",
    "# <6: pre weaning\n",
    "age_labels = [\"<= 6 months\", \"6 - 12 months\", \"12 - 18 months\", \"18 - 24 months\"]\n",
    "scores_abx_nth_samples[\"age_nth_abx_category\"] = pd.cut(\n",
    "    scores_abx_nth_samples[\"age_nth_abx\"], bins=bins_age, labels=age_labels, right=False\n",
    ")\n",
    "\n",
    "scores_abx_nth_samples[\"age_nth_abx_category\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for a in age_labels:\n",
    "    print(a)\n",
    "    # evaluation_path_bin = f\"{evaluation_path}age_bins{i}/\"\n",
    "\n",
    "    # age at time of abx exposure should match a\n",
    "    scores_abx_nth_samples_age = scores_abx_nth_samples.loc[\n",
    "        scores_abx_nth_samples[\"age_nth_abx_category\"] == a\n",
    "    ].copy()\n",
    "\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_age,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=score_col,\n",
    "        n=n,\n",
    "        path_to_save=None,\n",
    "        flag=split,\n",
    "        tag=f\"age: {a}\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples,\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 1st abx: split by type of abx (top 4 distinct categories prescribed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "score_col = f\"score_{n}\"\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "    abx_scores_flat,\n",
    "    abx_df,\n",
    "    n=n,\n",
    "    min_samples=min_samples,\n",
    "    max_samples=max_samples,\n",
    "    group_samples=group_samples,\n",
    "    score_var=score_col,\n",
    ")\n",
    "\n",
    "scores_abx_nth_samples[\"abx_type\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select types to look for\n",
    "abx_types = [\"Penicillin\", \"Cephalosporine\", \"Cotrimoxazole\", \"Macrolide\"]\n",
    "abx_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for abx in abx_types:\n",
    "    print(abx)\n",
    "    abx_str = abx.lower().replace(\" \", \"_\").replace(\",\", \"_\")\n",
    "    # evaluation_path_abx = f\"{evaluation_path}abx_type_{abx_str}/\"\n",
    "\n",
    "    # age at time of abx exposure should match a\n",
    "    scores_abx_nth_samples_abx = scores_abx_nth_samples.loc[\n",
    "        scores_abx_nth_samples[\"abx_type\"].str.contains(abx)\n",
    "    ].copy()\n",
    "\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_abx,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=score_col,\n",
    "        n=n,\n",
    "        path_to_save=None,\n",
    "        flag=split,\n",
    "        tag=f\"Abx type: {abx}\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples,\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 1st abx: split by type of abx reason (top 4 distinct categories prescribed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "score_col = f\"score_{n}\"\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "    abx_scores_flat,\n",
    "    abx_df,\n",
    "    n=n,\n",
    "    min_samples=min_samples,\n",
    "    max_samples=max_samples,\n",
    "    group_samples=group_samples,\n",
    "    score_var=score_col,\n",
    ")\n",
    "print(scores_abx_nth_samples[\"abx_reason\"].value_counts(dropna=False))\n",
    "reasons = (\n",
    "    scores_abx_nth_samples[\"abx_reason\"]\n",
    "    .value_counts(dropna=False)\n",
    "    .iloc[:4]\n",
    "    .index.tolist()\n",
    ")\n",
    "reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in reasons:\n",
    "    print(r)\n",
    "    r_str = r.lower().replace(\" \", \"_\").replace(\",\", \"_\")\n",
    "    # evaluation_path_r = f\"{evaluation_path}abx_reason_{r_str}/\"\n",
    "\n",
    "    # age at time of abx exposure should match a\n",
    "    scores_abx_nth_samples_r = scores_abx_nth_samples.loc[\n",
    "        scores_abx_nth_samples[\"abx_reason\"] == r\n",
    "    ].copy()\n",
    "\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_r,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=score_col,\n",
    "        n=n,\n",
    "        path_to_save=None,\n",
    "        flag=split,\n",
    "        tag=f\"Abx reason: {r}\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples,\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score over age range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_splits_n_scores = {\n",
    "    \"train_noabx\": [\"score_1\", noabx_train],\n",
    "    \"val_noabx\": [\"score_1\", noabx_val],\n",
    "    \"abx_1st\": [\"score_1\", abx_scores_flat],\n",
    "    \"abx_2nd\": [\"score_2\", abx_scores_flat],\n",
    "    \"abx_3rd\": [\"score_3\", abx_scores_flat],\n",
    "}\n",
    "\n",
    "for name, v in dic_splits_n_scores.items():\n",
    "    score_col = v[0]\n",
    "    scores = v[1]\n",
    "    _plot_score_over_age(scores, score_col, name, evaluation_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "abx_1st vs. mean age at first abx exposure: 11.94 months      \n",
    "abx_2nd vs. mean age at first abx exposure: 14.10 months         \n",
    "abx_1st vs. mean age at first abx exposure: 15.41 months        \n",
    "\n",
    "<!-- TODO: add distribution plot above these plots for publication -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score overall - scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort both abx dataframes by increasing abx exposure in same way\n",
    "abx_scores_flat.sort_values(\n",
    "    [\n",
    "        \"abx_max_count_ever\",\n",
    "        \"max_abx_w_microbiome\",\n",
    "        \"host_id\",\n",
    "        \"day\",\n",
    "    ],\n",
    "    ascending=[True, True, True, True],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# sort abx_df accordingly\n",
    "# sort abx_df in same order and remove samples that don't exist in md_df\n",
    "abx_events = pd.DataFrame()\n",
    "abx_events[\"host_id\"] = abx_scores_flat[\"host_id\"].unique()\n",
    "abx_events = pd.merge(abx_events, abx_df, on=\"host_id\", how=\"left\")\n",
    "\n",
    "assert abx_events.host_id.unique().tolist() == abx_scores_flat.host_id.unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_splits = {\n",
    "    \"train_noabx\": [\"score_1\", noabx_train, None],\n",
    "    \"val_noabx\": [\"score_1\", noabx_val, None],\n",
    "    \"abx\": [\"score_1\", abx_scores_flat, abx_events],\n",
    "}\n",
    "\n",
    "display_scatterplot_w_scores(dic_splits, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_splits = {\n",
    "    \"abx_1st\": [\"score_1\", abx_scores_flat, abx_events],\n",
    "    \"abx_2nd\": [\"score_2\", abx_scores_flat, abx_events],\n",
    "    \"abx_3rd\": [\"score_3\", abx_scores_flat, abx_events],\n",
    "}\n",
    "\n",
    "display_scatterplot_w_scores(dic_splits, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# TODO: if ranges are no longer same (min-max) legend in above plot needs to be\n",
    "# TODO: adjusted\n",
    "abx_scores_flat[[\"score_1\", \"score_2\", \"score_3\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual trajectories: score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat, abx_events, \"P006862\", [\"score_1\", \"score_2\", \"score_3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_scores_flat.loc[abx_scores_flat.host_id == \"E024646\", \"abx_any_cumcount\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat, abx_events, \"E024646\", [\"score_1\", \"score_2\", \"score_3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_scores_flat.loc[abx_scores_flat.host_id == \"E009676\", \"abx_any_cumcount\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat, abx_events, \"E009676\", [\"score_1\", \"score_2\", \"score_3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_scores_flat.loc[abx_scores_flat.host_id == \"E004898\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat, abx_events, \"E004898\", [\"score_1\", \"score_2\", \"score_3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat, abx_events, \"E004628\", [\"score_1\", \"score_2\", \"score_3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat, abx_events, \"E021822\", [\"score_1\", \"score_2\", \"score_3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat, abx_events, \"E003188\", [\"score_1\", \"score_2\", \"score_3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### noabx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(noabx_train, None, \"E035134\", [\"score_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(noabx_train, None, \"E022497\", [\"score_1\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "njode_scores",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
