{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to evaluate inferred microbial anomaly scores\n",
    "\n",
    "To run this notebook you need to create and activate the following conda environment:\n",
    "\n",
    "```\n",
    "conda create --name score_eval numpy pandas matplotlib seaborn scipy ipython ipykernel -y\n",
    "conda activate score_eval\n",
    "pip install -e .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils_eval_score import (\n",
    "    _get_abx_info,\n",
    "    _get_all_scores,\n",
    "    _plot_score_after_nth_abx_exposure,\n",
    "    _plot_score_over_age,\n",
    "    _select_samples_around_nth_abx_exposure,\n",
    "    display_scatterplot_w_scores,\n",
    "    get_age_at_1st_2nd_3rd_abx_exposure,\n",
    "    plot_time_between_abx_exposures,\n",
    "    plot_trajectory,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# avg. number of days per month\n",
    "DAYS_PER_MONTH = 30.437"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER input: define the inferred model and linked datasets to evaluate here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT START\n",
    "# name of the model\n",
    "model_name = \"saved_models_microbial_novel_alpha_div/id-2_test\"\n",
    "# which model version to evaluate: \"best\" or \"last\"\n",
    "point_to_evaluate = \"best\"\n",
    "\n",
    "# name of feature dataset used for model\n",
    "ft_name = \"ft_vat19_anomaly_v20240806_entero_family\"\n",
    "# name of abx time-series used for model\n",
    "abx_ts_name = \"ts_vat19_abx_v20240806\"\n",
    "\n",
    "# limit evaluation to time range up to this many months (if None no limit is set\n",
    "# and all scores are evaluated)\n",
    "limit_months = 24.0\n",
    "\n",
    "# whether to group samples prior to abx exposure in analysis\n",
    "group_samples = False\n",
    "\n",
    "# how many samples prior and after abx exposure to consider\n",
    "min_samples = -3.0\n",
    "max_samples = 12.0\n",
    "#### USER INPUT END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_path = f\"../data/{model_name}/anomaly_detection/scores_{point_to_evaluate}/\"\n",
    "evaluation_path = (\n",
    "    f\"../data/{model_name}/anomaly_detection/evaluation_{point_to_evaluate}_overall/\"\n",
    ")\n",
    "\n",
    "if not os.path.exists(evaluation_path):\n",
    "    os.makedirs(evaluation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train\n",
    "scores_train = _get_all_scores(scores_path, \"train\", limit_months=limit_months)\n",
    "\n",
    "# get val\n",
    "scores_val = _get_all_scores(scores_path, \"val\", limit_months=limit_months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get noabx samples per split\n",
    "noabx_train = scores_train[~scores_train[\"abx\"]].copy()\n",
    "noabx_val = scores_val[~scores_val[\"abx\"]].copy()\n",
    "\n",
    "# select correct scores\n",
    "noabx_train.drop(columns=[\"score_2\", \"score_3\"], inplace=True)\n",
    "\n",
    "noabx_val.drop(columns=[\"score_2\", \"score_3\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all abx scores into one group: train + val\n",
    "# since none of the abx samples were used for training\n",
    "abx_scores_flat = scores_train[scores_train[\"abx\"]].copy()\n",
    "abx_scores_flat_val = scores_val[scores_val[\"abx\"]].copy()\n",
    "\n",
    "abx_scores_flat = pd.concat([abx_scores_flat, abx_scores_flat_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add metadata matching samples over time from ft\n",
    "ft_df = pd.read_csv(f\"../data/original_data/{ft_name}.tsv\", sep=\"\\t\", index_col=0)\n",
    "ft_df[\"age_days\"] = ft_df[\"age_days\"].astype(int)\n",
    "ft_df.rename(columns={\"age_days\": \"day\"}, inplace=True)\n",
    "\n",
    "cols_to_evaluate = [\n",
    "    \"abx_any_cumcount\",\n",
    "    \"abx_max_count_ever\",\n",
    "    \"abx_any_last_t_dmonths\",\n",
    "    \"abx_any_last_dur_days\",\n",
    "    \"geo_location_name\",\n",
    "]\n",
    "ft_df = ft_df[[\"day\", \"host_id\"] + cols_to_evaluate].copy()\n",
    "ft_df = ft_df.assign(\n",
    "    max_abx_w_microbiome=lambda df: df.groupby(\"host_id\")[\"abx_any_cumcount\"].transform(\n",
    "        \"max\"\n",
    "    ),\n",
    ")\n",
    "# add additional information to inferred scores\n",
    "print(abx_scores_flat.shape)\n",
    "abx_scores_flat = abx_scores_flat.merge(ft_df, on=[\"host_id\", \"day\"], how=\"left\")\n",
    "print(abx_scores_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get start of each abx course per host\n",
    "path_to_abx_ts = f\"../data/original_data/{abx_ts_name}.tsv\"\n",
    "abx_df = _get_abx_info(path_to_abx_ts, limit_months=limit_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get age at n-th abx exposures\n",
    "abx_age_at_all = get_age_at_1st_2nd_3rd_abx_exposure(abx_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after abx exposure 1st, 2nd and 3rd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score_1, score_2 and score_3 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get samples around n-th abx exposure\n",
    "for n in [1, 2, 3]:\n",
    "    score_col = f\"score_{n}\"\n",
    "    scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "        abx_scores_flat,\n",
    "        abx_df,\n",
    "        n=n,\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        group_samples=group_samples,\n",
    "        score_var=score_col,\n",
    "    )\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=score_col,\n",
    "        n=n,\n",
    "        path_to_save=evaluation_path,\n",
    "        flag=score_col,\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_between_abx_exposures(\n",
    "    abx_age_at_all, n0_label=\"1st\", n1_label=\"2nd\", path_to_save=evaluation_path\n",
    ")\n",
    "plt.show()\n",
    "plot_time_between_abx_exposures(\n",
    "    abx_age_at_all, n0_label=\"2nd\", n1_label=\"3rd\", path_to_save=evaluation_path\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score_1 only - for comparison with alpha diversity matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get samples around n-th abx exposure\n",
    "for n in [1, 2, 3]:\n",
    "    score_col = \"score_1\"\n",
    "    scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "        abx_scores_flat,\n",
    "        abx_df,\n",
    "        n=n,\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        group_samples=group_samples,\n",
    "        score_var=score_col,\n",
    "    )\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=score_col,\n",
    "        n=n,\n",
    "        path_to_save=evaluation_path,\n",
    "        flag=\"score_1_only\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 2nd abx: split by time since 1st abx exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_threshold = 8  # in months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_time_between = abx_age_at_all.copy()\n",
    "abx_time_between[\"time_since_1st\"] = (\n",
    "    abx_time_between[\"age_2nd_abx\"] - abx_time_between[\"age_1st_abx\"]\n",
    ")\n",
    "\n",
    "bins = [-float(\"inf\"), duration_threshold, float(\"inf\")]\n",
    "between_labels = [f\"<= {duration_threshold} months\", f\"> {duration_threshold} months\"]\n",
    "abx_time_between[\"time_since_1st_cat\"] = pd.cut(\n",
    "    abx_time_between[\"time_since_1st\"],\n",
    "    bins=bins,\n",
    "    labels=between_labels,\n",
    "    right=True,\n",
    ")\n",
    "abx_time_between.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get samples around n-th abx exposure\n",
    "n = 2\n",
    "i = 0\n",
    "score_col = f\"score_{n}\"\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "    abx_scores_flat,\n",
    "    abx_df,\n",
    "    n=n,\n",
    "    min_samples=min_samples,\n",
    "    max_samples=max_samples,\n",
    "    group_samples=group_samples,\n",
    "    score_var=score_col,\n",
    ")\n",
    "\n",
    "for cat in between_labels:\n",
    "    # filter only for scores of hosts where 2nd abx is in cat time duration\n",
    "    hosts = abx_time_between[abx_time_between[\"time_since_1st_cat\"] == cat][\n",
    "        \"host_id\"\n",
    "    ].unique()\n",
    "\n",
    "    scores_abx_nth_samples_f = scores_abx_nth_samples[\n",
    "        scores_abx_nth_samples[\"host_id\"].isin(hosts)\n",
    "    ].copy()\n",
    "    flag = f\"time_since_{n-1}th_{i}\"\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_f,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=score_col,\n",
    "        n=n,\n",
    "        path_to_save=evaluation_path,\n",
    "        flag=flag,\n",
    "        tag=f\"time since {n-1}-th: {cat}\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples,\n",
    "    )\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 1st abx: split by duration: < 7 days vs. >= 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "score_col = f\"score_{n}\"\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "    abx_scores_flat,\n",
    "    abx_df,\n",
    "    n=n,\n",
    "    min_samples=min_samples,\n",
    "    max_samples=max_samples,\n",
    "    group_samples=group_samples,\n",
    "    score_var=score_col,\n",
    ")\n",
    "\n",
    "# bin duration into short, mid and long duration\n",
    "scores_abx_nth_samples[\"abx_any_last_dur_days\"].hist(bins=10)\n",
    "\n",
    "bins = [-float(\"inf\"), 6, float(\"inf\")]\n",
    "dur_labels = [\"< 6 days\", \">= 6 days\"]\n",
    "scores_abx_nth_samples[\"abx_duration_category\"] = pd.cut(\n",
    "    scores_abx_nth_samples[\"abx_any_last_dur_days\"],\n",
    "    bins=bins,\n",
    "    labels=dur_labels,\n",
    "    right=False,\n",
    ")\n",
    "\n",
    "scores_abx_nth_samples[\"abx_duration_category\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for dur in dur_labels:\n",
    "    print(dur)\n",
    "    # evaluation_path_bin = f\"{evaluation_path}duration_bins{i}/\"\n",
    "    host_w_dur = (\n",
    "        scores_abx_nth_samples.loc[\n",
    "            scores_abx_nth_samples[\"abx_duration_category\"] == dur, \"host_id\"\n",
    "        ]\n",
    "        .unique()\n",
    "        .tolist()\n",
    "    )\n",
    "    scores_abx_nth_samples_dur = scores_abx_nth_samples.loc[\n",
    "        scores_abx_nth_samples[\"host_id\"].isin(host_w_dur)\n",
    "    ].copy()\n",
    "    flag_dur = f\"dur_{i}\"\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_dur,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=score_col,\n",
    "        n=n,\n",
    "        path_to_save=evaluation_path,\n",
    "        flag=flag_dur,\n",
    "        tag=f\"duration: {dur}\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples,\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 1st abx: split by time of life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "score_col = f\"score_{n}\"\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "    abx_scores_flat,\n",
    "    abx_df,\n",
    "    n=n,\n",
    "    min_samples=min_samples,\n",
    "    max_samples=max_samples,\n",
    "    group_samples=group_samples,\n",
    "    score_var=score_col,\n",
    ")\n",
    "\n",
    "# bin duration into short, mid and long duration\n",
    "scores_abx_nth_samples[\"age_nth_abx\"].hist(bins=24)\n",
    "\n",
    "bins_age = [-float(\"inf\"), 6, 12, 18, float(\"inf\")]\n",
    "# <6: pre weaning\n",
    "age_labels = [\"<= 6 months\", \"6 - 12 months\", \"12 - 18 months\", \"18 - 24 months\"]\n",
    "scores_abx_nth_samples[\"age_nth_abx_category\"] = pd.cut(\n",
    "    scores_abx_nth_samples[\"age_nth_abx\"], bins=bins_age, labels=age_labels, right=False\n",
    ")\n",
    "\n",
    "scores_abx_nth_samples[\"age_nth_abx_category\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for a in age_labels:\n",
    "    print(a)\n",
    "    # evaluation_path_bin = f\"{evaluation_path}age_bins{i}/\"\n",
    "\n",
    "    # age at time of abx exposure should match a\n",
    "    scores_abx_nth_samples_age = scores_abx_nth_samples.loc[\n",
    "        scores_abx_nth_samples[\"age_nth_abx_category\"] == a\n",
    "    ].copy()\n",
    "    flag_age = f\"age_{i}\"\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_age,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=score_col,\n",
    "        n=n,\n",
    "        path_to_save=evaluation_path,\n",
    "        flag=flag_age,\n",
    "        tag=f\"age: {a}\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples,\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 1st abx: split by type of abx (top 1 vs. others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "score_col = f\"score_{n}\"\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "    abx_scores_flat,\n",
    "    abx_df,\n",
    "    n=n,\n",
    "    min_samples=min_samples,\n",
    "    max_samples=max_samples,\n",
    "    group_samples=group_samples,\n",
    "    score_var=score_col,\n",
    ")\n",
    "\n",
    "# add top 1 vs. others\n",
    "scores_abx_nth_samples[\"abx_type_cat\"] = scores_abx_nth_samples[\"abx_type\"].apply(\n",
    "    lambda x: \"Penicillin\" if x == \"Penicillin\" else \"Others\"\n",
    ")\n",
    "scores_abx_nth_samples[\"abx_type_cat\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select types to look for\n",
    "abx_types = scores_abx_nth_samples[\"abx_type_cat\"].unique().tolist()\n",
    "# abx_types = [\"Penicillin\", \"Cephalosporine\", \"Cotrimoxazole\", \"Macrolide\"]\n",
    "abx_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_col = \"abx_type_cat\"\n",
    "# abx_col = \"abx_type\"\n",
    "for abx in abx_types:\n",
    "    print(abx)\n",
    "    abx_str = abx.lower().replace(\" \", \"_\").replace(\",\", \"_\")\n",
    "    flag_abx = f\"abx_type_{abx_str}\"\n",
    "    # evaluation_path_abx = f\"{evaluation_path}abx_type_{abx_str}/\"\n",
    "\n",
    "    # age at time of abx exposure should match a\n",
    "    scores_abx_nth_samples_abx = scores_abx_nth_samples.loc[\n",
    "        scores_abx_nth_samples[abx_col].str.contains(abx)\n",
    "    ].copy()\n",
    "\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_abx,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=score_col,\n",
    "        n=n,\n",
    "        path_to_save=evaluation_path,\n",
    "        flag=flag_abx,\n",
    "        tag=f\"Abx type: {abx}\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples,\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 1st abx: split by type of abx reason (top 1 vs. others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "score_col = f\"score_{n}\"\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "    abx_scores_flat,\n",
    "    abx_df,\n",
    "    n=n,\n",
    "    min_samples=min_samples,\n",
    "    max_samples=max_samples,\n",
    "    group_samples=group_samples,\n",
    "    score_var=score_col,\n",
    ")\n",
    "# top 1 vs. others\n",
    "print(scores_abx_nth_samples[\"abx_reason\"].value_counts(dropna=False))\n",
    "\n",
    "scores_abx_nth_samples[\"abx_reason_cat\"] = scores_abx_nth_samples[\"abx_reason\"].apply(\n",
    "    lambda x: \"Otitis media\" if x == \"Otitis media\" else \"Others\"\n",
    ")\n",
    "print(scores_abx_nth_samples[\"abx_reason_cat\"].value_counts(dropna=False))\n",
    "\n",
    "reasons = scores_abx_nth_samples[\"abx_reason_cat\"].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # top 4 reasons\n",
    "# reasons = (\n",
    "#     scores_abx_nth_samples[\"abx_reason\"]\n",
    "#     .value_counts(dropna=False)\n",
    "#     .iloc[:4]\n",
    "#     .index.tolist()\n",
    "# )\n",
    "# reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in reasons:\n",
    "    print(r)\n",
    "    r_str = r.lower().replace(\" \", \"_\").replace(\",\", \"_\")\n",
    "    # evaluation_path_r = f\"{evaluation_path}abx_reason_{r_str}/\"\n",
    "\n",
    "    # age at time of abx exposure should match a\n",
    "    scores_abx_nth_samples_r = scores_abx_nth_samples.loc[\n",
    "        scores_abx_nth_samples[\"abx_reason\"] == r\n",
    "    ].copy()\n",
    "    flag_reason = f\"abx_reason_{r_str}\"\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_r,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=score_col,\n",
    "        n=n,\n",
    "        path_to_save=evaluation_path,\n",
    "        flag=flag_reason,\n",
    "        tag=f\"Abx reason: {r}\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples,\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score over age range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_splits_n_scores = {\n",
    "    \"train_noabx\": [\"score_1\", noabx_train, None],\n",
    "    \"val_noabx\": [\"score_1\", noabx_val, None],\n",
    "    \"abx_1st\": [\"score_1\", abx_scores_flat, abx_age_at_all[\"age_1st_abx\"]],\n",
    "    \"abx_2nd\": [\"score_2\", abx_scores_flat, abx_age_at_all[\"age_2nd_abx\"]],\n",
    "    \"abx_3rd\": [\"score_3\", abx_scores_flat, abx_age_at_all[\"age_3rd_abx\"]],\n",
    "}\n",
    "\n",
    "for name, v in dic_splits_n_scores.items():\n",
    "    score_col = v[0]\n",
    "    scores = v[1]\n",
    "    abx_age_values = v[2]\n",
    "    _plot_score_over_age(scores, score_col, name, evaluation_path, abx_age_values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score overall - scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort both abx dataframes by increasing abx exposure in same way\n",
    "abx_scores_flat.sort_values(\n",
    "    [\n",
    "        \"abx_max_count_ever\",\n",
    "        \"max_abx_w_microbiome\",\n",
    "        \"host_id\",\n",
    "        \"day\",\n",
    "    ],\n",
    "    ascending=[True, True, True, True],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# sort abx_df accordingly\n",
    "# sort abx_df in same order and remove samples that don't exist in md_df\n",
    "abx_events = pd.DataFrame()\n",
    "abx_events[\"host_id\"] = abx_scores_flat[\"host_id\"].unique()\n",
    "abx_events = pd.merge(abx_events, abx_df, on=\"host_id\", how=\"left\")\n",
    "\n",
    "assert abx_events.host_id.unique().tolist() == abx_scores_flat.host_id.unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_splits = {\n",
    "    \"train_noabx\": [\"score_1\", noabx_train, None],\n",
    "    \"val_noabx\": [\"score_1\", noabx_val, None],\n",
    "    \"abx\": [\"score_1\", abx_scores_flat, abx_events],\n",
    "}\n",
    "\n",
    "display_scatterplot_w_scores(\n",
    "    dic_splits, False, path_to_output=evaluation_path, flag=\"noabx_vs_abx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_splits = {\n",
    "    \"abx_1st\": [\"score_1\", abx_scores_flat, abx_events],\n",
    "    \"abx_2nd\": [\"score_2\", abx_scores_flat, abx_events],\n",
    "    \"abx_3rd\": [\"score_3\", abx_scores_flat, abx_events],\n",
    "}\n",
    "\n",
    "display_scatterplot_w_scores(\n",
    "    dic_splits, False, True, path_to_output=evaluation_path, flag=\"all_abx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual trajectories: score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat,\n",
    "    abx_events,\n",
    "    \"P006862\",\n",
    "    [\"score_1\", \"score_2\", \"score_3\"],\n",
    "    path_to_output=evaluation_path,\n",
    "    flag=\"all_scores\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_scores_flat.loc[abx_scores_flat.host_id == \"E024646\", \"abx_any_cumcount\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat,\n",
    "    abx_events,\n",
    "    \"E024646\",\n",
    "    [\"score_1\", \"score_2\", \"score_3\"],\n",
    "    path_to_output=evaluation_path,\n",
    "    flag=\"all_scores\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_scores_flat.loc[abx_scores_flat.host_id == \"E009676\", \"abx_any_cumcount\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat,\n",
    "    abx_events,\n",
    "    \"E009676\",\n",
    "    [\"score_1\", \"score_2\", \"score_3\"],\n",
    "    path_to_output=evaluation_path,\n",
    "    flag=\"all_scores\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_scores_flat.loc[abx_scores_flat.host_id == \"E004898\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat,\n",
    "    abx_events,\n",
    "    \"E004898\",\n",
    "    [\"score_1\", \"score_2\", \"score_3\"],\n",
    "    path_to_output=evaluation_path,\n",
    "    flag=\"all_scores\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat,\n",
    "    abx_events,\n",
    "    \"E004628\",\n",
    "    [\"score_1\", \"score_2\", \"score_3\"],\n",
    "    path_to_output=evaluation_path,\n",
    "    flag=\"all_scores\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat,\n",
    "    abx_events,\n",
    "    \"E021822\",\n",
    "    [\"score_1\", \"score_2\", \"score_3\"],\n",
    "    path_to_output=evaluation_path,\n",
    "    flag=\"all_scores\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    abx_scores_flat,\n",
    "    abx_events,\n",
    "    \"E003188\",\n",
    "    [\"score_1\", \"score_2\", \"score_3\"],\n",
    "    path_to_output=evaluation_path,\n",
    "    flag=\"all_scores\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### noabx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    noabx_train,\n",
    "    None,\n",
    "    \"E035134\",\n",
    "    [\"score_1\"],\n",
    "    path_to_output=evaluation_path,\n",
    "    flag=\"noabx_score1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(\n",
    "    noabx_train,\n",
    "    None,\n",
    "    \"E022497\",\n",
    "    [\"score_1\"],\n",
    "    path_to_output=evaluation_path,\n",
    "    flag=\"noabx_score1\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "njode_scores",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
