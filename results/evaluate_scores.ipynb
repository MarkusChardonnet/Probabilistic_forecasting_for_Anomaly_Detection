{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to evaluate inferred microbial anomaly scores\n",
    "\n",
    "To run this notebook you need to create and activate the following conda environment:\n",
    "\n",
    "```\n",
    "conda create --name score_eval numpy pandas matplotlib seaborn scipy ipython ipykernel -y\n",
    "conda activate score_eval\n",
    "pip install -e .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils_eval_score import (\n",
    "    _transform_scores,\n",
    "    _plot_score_over_age, \n",
    "    _get_abx_info,\n",
    "    _select_samples_around_nth_abx_exposure,\n",
    "    _plot_score_after_nth_abx_exposure,\n",
    "    display_scatterplot_w_scores,\n",
    "    plot_trajectory\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# avg. number of days per month\n",
    "DAYS_PER_MONTH = 30.437"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER input: define the inferred model and linked datasets to evaluate here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT START\n",
    "# name of the model\n",
    "model_name = \"saved_models_microbial_alpha_div/id-102\"\n",
    "# which model version to evaluate: \"best\" or \"last\"\n",
    "point_to_evaluate = \"last\"\n",
    "\n",
    "# name of feature dataset used for model\n",
    "ft_name = \"ft_vat19_anomaly_v20240105_genus\"\n",
    "# name of abx time-series used for model\n",
    "abx_ts_name = \"ts_vat19_abx_v20240105\"\n",
    "\n",
    "#### USER INPUT END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_path = f\"../data/{model_name}/anomaly_detection/scores_{point_to_evaluate}/\"\n",
    "evaluation_path = f\"../data/{model_name}/anomaly_detection/evaluation_{point_to_evaluate}/\"\n",
    "\n",
    "if not os.path.exists(evaluation_path):\n",
    "    os.makedirs(evaluation_path)\n",
    "\n",
    "split = \"both\"\n",
    "# get train\n",
    "train_ad_scores = pd.read_csv(f\"{scores_path}train_ad_scores.csv\")\n",
    "scores_train = _transform_scores(train_ad_scores)\n",
    "\n",
    "# get val\n",
    "val_ad_scores = pd.read_csv(f\"{scores_path}val_ad_scores.csv\")\n",
    "scores_val = _transform_scores(val_ad_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get noabx samples per split\n",
    "noabx_train = scores_train[~scores_train[\"abx\"]].copy()\n",
    "noabx_val = scores_val[~scores_val[\"abx\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all abx scores into one group: train + val\n",
    "abx_scores_flat = scores_train[scores_train[\"abx\"]].copy()\n",
    "abx_scores_flat_val = scores_val[scores_val[\"abx\"]].copy()\n",
    "\n",
    "abx_scores_flat = pd.concat([abx_scores_flat, abx_scores_flat_val])\n",
    "\n",
    "# keep only rows that have a score\n",
    "abx_scores_flat = abx_scores_flat[abx_scores_flat.score.notnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add metadata matching samples over time from ft\n",
    "ft_df = pd.read_csv(f\"../data/original_data/{ft_name}.tsv\", sep=\"\\t\", index_col=0)\n",
    "ft_df[\"age_days\"] = ft_df[\"age_days\"].astype(int)\n",
    "ft_df.rename(columns={\"age_days\": \"day\"}, inplace=True)\n",
    "\n",
    "cols_to_evaluate = [\"abx_any_cumcount\", \"abx_max_count_ever\", \"abx_any_last_t_dmonths\", \"abx_any_last_dur_days\", \"geo_location_name\"]\n",
    "ft_df = ft_df[[\"day\", \"host_id\"] + cols_to_evaluate].copy()\n",
    "ft_df = ft_df.assign(\n",
    "    max_abx_w_microbiome=lambda df: df.groupby(\"host_id\")[\"abx_any_cumcount\"].transform(\n",
    "        \"max\"\n",
    "    ),\n",
    ")\n",
    "# add additional information to inferred scores\n",
    "abx_scores_flat = abx_scores_flat.merge(ft_df, on=[\"host_id\", \"day\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after abx exposure 1st, 2nd and 3rd\n",
    "\n",
    "abx train + val were both not used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_abx_ts = f\"../data/original_data/{abx_ts_name}.tsv\"\n",
    "abx_df = _get_abx_info(path_to_abx_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get samples around n-th abx exposure\n",
    "for n in [1, 2, 3]:\n",
    "    scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "        abx_scores_flat, abx_df, n=n\n",
    "    )\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=\"score\",\n",
    "        n=n,\n",
    "        path_to_save=evaluation_path,\n",
    "        flag=split,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 1st abx: split by duration: < 7 days vs. >= 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "        abx_scores_flat, abx_df, n=n)\n",
    "\n",
    "# bin duration into short, mid and long duration\n",
    "scores_abx_nth_samples[\"abx_any_last_dur_days\"].hist(bins=10)\n",
    "\n",
    "bins = [-float('inf'), 6, float('inf')]\n",
    "dur_labels = ['< 6 days', '>= 6 days']\n",
    "scores_abx_nth_samples['abx_duration_category'] = pd.cut(scores_abx_nth_samples['abx_any_last_dur_days'], bins=bins, labels=dur_labels, right=False)\n",
    "\n",
    "scores_abx_nth_samples['abx_duration_category'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for dur in dur_labels:\n",
    "    print(dur)\n",
    "    evaluation_path_bin = f\"{evaluation_path}duration_bins{i}_\"\n",
    "    host_w_dur = scores_abx_nth_samples.loc[scores_abx_nth_samples['abx_duration_category'] == dur, \"host_id\"].unique().tolist()\n",
    "    scores_abx_nth_samples_dur = scores_abx_nth_samples.loc[scores_abx_nth_samples['host_id'].isin(host_w_dur)].copy()\n",
    "\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_dur,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=\"score\",\n",
    "        n=n,\n",
    "        path_to_save=None,\n",
    "        flag=split,\n",
    "        tag = f\"duration: {dur}\"\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score after 1st abx: split by time of life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "        abx_scores_flat, abx_df, n=n)\n",
    "\n",
    "# bin duration into short, mid and long duration\n",
    "scores_abx_nth_samples[\"age_nth_abx\"].hist(bins=24)\n",
    "\n",
    "bins_age = [-float('inf'), 12, float('inf')]\n",
    "# <6: pre weaning\n",
    "age_labels = ['< 12 months', '>= 12 months']\n",
    "scores_abx_nth_samples['age_nth_abx_category'] = pd.cut(scores_abx_nth_samples['age_nth_abx'], bins=bins_age, labels=age_labels, right=False)\n",
    "\n",
    "scores_abx_nth_samples['age_nth_abx_category'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for a in age_labels:\n",
    "    print(a)\n",
    "    evaluation_path_bin = f\"{evaluation_path}age_bins{i}_\"\n",
    "    \n",
    "    # age at time of abx exposure should match a\n",
    "    scores_abx_nth_samples_age = scores_abx_nth_samples.loc[scores_abx_nth_samples['age_nth_abx_category']==a].copy()\n",
    "\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_age,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=\"score\",\n",
    "        n=n,\n",
    "        path_to_save=None,\n",
    "        flag=split,\n",
    "        tag = f\"age: {a}\"\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score split by geo_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_abx_nth_samples['geo_location_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for c in scores_abx_nth_samples['geo_location_name'].unique():\n",
    "    evaluation_path_bin = f\"{evaluation_path}country{i}_\"\n",
    "    \n",
    "    # age at time of abx exposure should match a\n",
    "    scores_abx_nth_samples_c = scores_abx_nth_samples.loc[scores_abx_nth_samples['geo_location_name']==c].copy()\n",
    "\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_c,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=\"score\",\n",
    "        n=n,\n",
    "        path_to_save=None,\n",
    "        flag=split,\n",
    "        tag = f\"country: {c}\"\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score over abx characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis = \"score\"\n",
    "ylabel = f\"# samples w {y_axis}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abx_any_last_t_dmonths vs. score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Scores depending on how long ago abx exposure was\"\n",
    "x_axis = \"abx_any_last_t_dmonths\"\n",
    "xlabel = x_axis\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(25, 6), dpi=400, sharex=True\n",
    "    )\n",
    "abx_scores_flat_c = abx_scores_flat.copy()\n",
    "abx_scores_flat_c.fillna({x_axis: -0.5}, inplace=True)\n",
    "sns.boxplot(x=x_axis, y=y_axis, data=abx_scores_flat_c, color=\"skyblue\", ax=axs[0])\n",
    "grouped_counts = abx_scores_flat_c.groupby(x_axis)[y_axis].count().reset_index(name=\"counts\")\n",
    "sns.barplot(x=x_axis, y=\"counts\", data=grouped_counts, color=\"peachpuff\", ax=axs[1])\n",
    "\n",
    "plt.title(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abx_any_last_dur_days vs. score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Scores depending on how long abx exposure lasted\"\n",
    "x_axis = \"abx_any_last_dur_days\"\n",
    "xlabel = x_axis\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(25, 6), dpi=400, sharex=True\n",
    "    )\n",
    "abx_scores_flat_c = abx_scores_flat.copy()\n",
    "abx_scores_flat_c.fillna({x_axis: -1.0}, inplace=True)\n",
    "sns.boxplot(x=x_axis, y=y_axis, data=abx_scores_flat_c, color=\"skyblue\", ax=axs[0])\n",
    "grouped_counts = abx_scores_flat_c.groupby(x_axis)[y_axis].count().reset_index(name=\"counts\")\n",
    "sns.barplot(x=x_axis, y=\"counts\", data=grouped_counts, color=\"peachpuff\", ax=axs[1])\n",
    "\n",
    "plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score over age range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_splits_n_scores = {\n",
    "    \"train_noabx\": noabx_train,\n",
    "    \"val_noabx\": noabx_val,\n",
    "    \"abx\": abx_scores_flat\n",
    "}\n",
    "\n",
    "for name, scores in dic_splits_n_scores.items():\n",
    "    _plot_score_over_age(scores, name, evaluation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score overall - scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort both abx dataframes by increasing abx exposure in same way\n",
    "abx_scores_flat.sort_values(\n",
    "    [\n",
    "        \"abx_max_count_ever\",\n",
    "        \"max_abx_w_microbiome\",\n",
    "        \"host_id\",\n",
    "        \"day\",\n",
    "    ],\n",
    "    ascending=[True, True, True, True],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# sort abx_df accordingly\n",
    "# sort abx_df in same order and remove samples that don't exist in md_df\n",
    "abx_events = pd.DataFrame()\n",
    "abx_events[\"host_id\"] = abx_scores_flat[\"host_id\"].unique()\n",
    "abx_events = pd.merge(abx_events, abx_df, on=\"host_id\", how=\"left\")\n",
    "\n",
    "assert abx_events.host_id.unique().tolist() == abx_scores_flat.host_id.unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_splits = {\n",
    "    \"train_noabx\": [noabx_train, None],\n",
    "    \"val_noabx\": [noabx_val, None],\n",
    "    \"abx\": [abx_scores_flat, abx_events]\n",
    "}\n",
    "\n",
    "display_scatterplot_w_scores(dic_splits, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual trajectories: score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(abx_scores_flat,abx_events,  \"E004628\", \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(abx_scores_flat, abx_events,  \"E021822\", \"score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### noabx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(noabx_train, None,  \"E035134\", \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(noabx_train, None,  \"E022497\", \"score\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "njode_scores",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
