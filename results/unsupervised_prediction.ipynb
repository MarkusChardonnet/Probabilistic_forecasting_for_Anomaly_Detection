{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to evaluate anomaly scores by unsupervised prediction performance\n",
    "\n",
    "To run this notebook you need to create and activate the following conda environment:\n",
    "\n",
    "```\n",
    "conda create --name score_eval -c conda-forge -c defaults numpy pandas matplotlib seaborn scipy scikit-learn ipython ipykernel -y\n",
    "conda activate score_eval\n",
    "pip install -e .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils_eval_score import (\n",
    "    _filter_hosts_w_microbiome_samples_prior_to_abx,\n",
    "    get_scores_n_abx_info,\n",
    ")\n",
    "from src.utils_prediction import (\n",
    "    report_metrics,\n",
    "    train_n_evaluate_rf_model,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER input: define the inferred model and linked datasets to evaluate here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT START\n",
    "# name of the model\n",
    "model_name = \"saved_models_microbial_novel_alpha_div2/id-55\"\n",
    "# which model version to evaluate: \"best\" or \"last\"\n",
    "point_to_evaluate = \"best\"\n",
    "\n",
    "# name of feature dataset used for model\n",
    "ft_name = \"ft_vat19_anomaly_v20240806_entero_genus\"\n",
    "# path to abx time-series file\n",
    "path_to_abx_data = \"../data/original_data/\"\n",
    "# name of abx time-series used for model\n",
    "abx_ts_name = \"ts_vat19_abx_v20240806\"\n",
    "\n",
    "# limit evaluation to time range up to this many months (if None no limit is set\n",
    "# and all scores are evaluated)\n",
    "limit_months = 24.0\n",
    "\n",
    "# scaling factor options:\n",
    "scaling_factors_used = True\n",
    "\n",
    "# if scaling_factors_used is True, then the following options are required:\n",
    "# non-centered = \"nc_std\" or centered = \"std\"\n",
    "stddev_type = \"nc_std\"\n",
    "# moving average window size: 30 or 10\n",
    "moving_avg = 10\n",
    "# whether to include duplicates: \"--RD-True\" or \"\"\n",
    "duplicates = \"\"\n",
    "\n",
    "#### USER INPUT END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = f\"../data/{model_name}/anomaly_detection/\"\n",
    "\n",
    "if scaling_factors_used:\n",
    "    print(\"Scaling factors used.\")\n",
    "    folder_name = f\"using-SF_{stddev_type}_z_scores--moving_avg-{moving_avg}-cummax-lower_bound-1{duplicates}\"\n",
    "\n",
    "    scores_path = f\"{base_path}scores_{point_to_evaluate}_normal/{folder_name}/\"\n",
    "    evaluation_path = f\"{base_path}evaluation_{point_to_evaluate}_unsupervised_pred_{stddev_type}_ma{moving_avg}{duplicates.replace(\"-\", \"_\").lower()}/\"\n",
    "else:\n",
    "    scores_path = f\"{base_path}scores_{point_to_evaluate}_normal/\"\n",
    "    evaluation_path = f\"{base_path}evaluation_{point_to_evaluate}_unsupervised_pred/\"\n",
    "\n",
    "if not os.path.exists(evaluation_path):\n",
    "    os.makedirs(evaluation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scores\n",
    "noabx_train, noabx_val, abx_scores_flat, abx_df, abx_age_at_all = get_scores_n_abx_info(\n",
    "    scores_path, ft_name, limit_months, abx_ts_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define true targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure correct sorting\n",
    "abx_scores_flat.sort_values(\n",
    "    [\n",
    "        \"abx_max_count_ever\",\n",
    "        \"max_abx_w_microbiome\",\n",
    "        \"host_id\",\n",
    "        \"day\",\n",
    "    ],\n",
    "    ascending=[True, True, True, True],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter abx hosts by at least 1 microbiome sample prior to 1st abx exposure\n",
    "print(abx_scores_flat.shape)\n",
    "abx_scores_flat_f = _filter_hosts_w_microbiome_samples_prior_to_abx(\n",
    "    abx_scores_flat, abx_age_at_all\n",
    ")\n",
    "abx_scores_flat_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_scores_flat_f[\"true_target\"] = np.nan\n",
    "\n",
    "# ! define true positives: 1st observed sample in first 1-3 months after 1st abx exposure\n",
    "# select samples in first 3 months after 1st abx exposure\n",
    "# * 1st abx exposure: abx_scores_flat_f[\"abx_any_cumcount\"] == 1\n",
    "# * any abx exposure: abx_scores_flat_f[\"abx_any_cumcount\"] > 0\n",
    "samples_after_1st = (abx_scores_flat_f[\"abx_any_cumcount\"] == 1) & (\n",
    "    abx_scores_flat_f[\"abx_any_last_t_dmonths\"] <= 3.0\n",
    ")\n",
    "\n",
    "# identify first sample after 1st abx exposure per host\n",
    "first_sample_idx = (\n",
    "    abx_scores_flat_f[samples_after_1st]\n",
    "    .groupby(\"host_id\")[\"abx_any_last_t_dmonths\"]\n",
    "    .idxmin()\n",
    ")\n",
    "# * any sample after abx: use samples_after_1st directly instesad of first_sample_idx\n",
    "\n",
    "# Set 'true_target' to True for these samples\n",
    "abx_scores_flat_f.loc[first_sample_idx, \"true_target\"] = 1\n",
    "\n",
    "# ! define true negatives: samples with abx_cumcount == 0\n",
    "# TODO: add a prior sample!\n",
    "abx_scores_flat_f.loc[abx_scores_flat_f[\"abx_any_cumcount\"] == 0, \"true_target\"] = 0\n",
    "\n",
    "abx_scores_flat_f[\"true_target\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only samples with true_target\n",
    "unsupervised_subset = abx_scores_flat_f[abx_scores_flat_f[\"true_target\"].notna()].copy()\n",
    "print(unsupervised_subset[\"true_target\"].value_counts(dropna=False))\n",
    "unsupervised_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define features needed for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get increase in score + alpha diversity from one step to the next and time\n",
    "# duration between scores\n",
    "unsupervised_subset = (\n",
    "    unsupervised_subset.groupby(\"host_id\")\n",
    "    .apply(\n",
    "        lambda x: x.assign(\n",
    "            # relative score increase: now / previous\n",
    "            score_0_rel_change=x[\"score_0\"] / x[\"score_0\"].shift(1),\n",
    "            # diff in time between samples:\n",
    "            month5_bin_diff=x[\"month5_bin\"].diff(),\n",
    "            # former alpha diversity value\n",
    "            div_alpha_faith_pd_before=x[\"div_alpha_faith_pd\"].shift(1),\n",
    "        ),\n",
    "        include_groups=False,\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score-based predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S1: Set absolute threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_absolute = pd.DataFrame()\n",
    "df_results_absolute.index.name = \"quantile\"\n",
    "\n",
    "for q in reversed([0.7, 0.8, 0.9, 0.95, 0.97, 0.99]):\n",
    "    unsupervised_subset_th = unsupervised_subset.copy()\n",
    "\n",
    "    # define predicted target: threshold inferred from noabx validation set\n",
    "    print(f\"Quantile: {q}\")\n",
    "    thresh = noabx_val[\"score_0\"].quantile(q)\n",
    "    unsupervised_subset_th[\"pred_target\"] = unsupervised_subset_th[\"score_0\"] > thresh\n",
    "\n",
    "    # evaluate classification\n",
    "    df_results_absolute = report_metrics(\n",
    "        unsupervised_subset_th[\"true_target\"],\n",
    "        unsupervised_subset_th[\"pred_target\"],\n",
    "        df_results_absolute,\n",
    "        q,\n",
    "    )\n",
    "\n",
    "df_results_absolute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S2: Set relative score increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_relative = pd.DataFrame()\n",
    "df_results_relative.index.name = \"rel_increase\"\n",
    "\n",
    "for rel_inc in reversed([4, 3, 2.0, 1.75, 1.5, 1.4, 1.3, 1.2, 1.1, 1.05]):\n",
    "    unsupervised_subset_rel = unsupervised_subset.copy()\n",
    "\n",
    "    # define predicted target: rel_inc-ing of score within 3 months\n",
    "    print(f\"Relative increase: {rel_inc}\")\n",
    "\n",
    "    unsupervised_subset_rel[\"pred_target\"] = 0\n",
    "\n",
    "    pred_true = (unsupervised_subset_rel[\"score_0_rel_change\"] >= rel_inc) & (\n",
    "        unsupervised_subset_rel[\"month5_bin_diff\"] <= 3.0\n",
    "    )\n",
    "    unsupervised_subset_rel.loc[pred_true, \"pred_target\"] = 1\n",
    "\n",
    "    # evaluate classification\n",
    "    df_results_relative = report_metrics(\n",
    "        unsupervised_subset_rel[\"true_target\"],\n",
    "        unsupervised_subset_rel[\"pred_target\"],\n",
    "        df_results_relative,\n",
    "        rel_inc,\n",
    "    )\n",
    "\n",
    "df_results_relative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3: RF-based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_ml = train_n_evaluate_rf_model(\n",
    "    \"true_target\", [\"score_0\"], unsupervised_subset\n",
    ")\n",
    "df_results_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1: Set absolute threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2: Set relative threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B3: RF-based classifier : fully static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts_for_b3_rf_static = [\n",
    "    \"month_bin\",\n",
    "    \"diet_milk\",\n",
    "    \"diet_weaning\",\n",
    "    \"delivery_mode\",\n",
    "    \"div_alpha_faith_pd\",\n",
    "]\n",
    "\n",
    "df_results_rf_static = train_n_evaluate_rf_model(\n",
    "    \"true_target\", fts_for_b3_rf_static, unsupervised_subset\n",
    ")\n",
    "df_results_rf_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts_for_b3_rf_semi_static = [\n",
    "    \"month_bin\",\n",
    "    \"diet_milk\",\n",
    "    \"diet_weaning\",\n",
    "    \"delivery_mode\",\n",
    "    \"div_alpha_faith_pd\",\n",
    "    \"div_alpha_faith_pd_before\",\n",
    "]\n",
    "\n",
    "df_results_rf_semi_static = train_n_evaluate_rf_model(\n",
    "    \"true_target\", fts_for_b3_rf_semi_static, unsupervised_subset\n",
    ")\n",
    "df_results_rf_semi_static"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "score_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
