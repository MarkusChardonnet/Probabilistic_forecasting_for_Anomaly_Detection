{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to evaluate characteristics of individual anomaly trajectories\n",
    "\n",
    "\n",
    "Main difference to evaluation in `evaluate_scores.iypnb`: there we performed a population view taking into account all samples that we have, here it is an individual trajectory perspective. This individual trajectory perspective yields a much smaller sample size due to the restriction that each analyzed trajectory must have a microbial sample in 3 months preceding abx exposure (at -1.0) as well as at least one sample after exposure:\n",
    "\n",
    "| n | 1 |2 |\n",
    "|----------|----------|----------|\n",
    "| # infants     | 49 |30 |\n",
    "| # infants w score increased + w/o | 21 + 28 |11 + 19 |\n",
    "\n",
    "As contrast, sample size in population view performed in `evaluate_scores.iypnb`:\n",
    "\n",
    "| Characteristic | n = 1 | n = 2 |\n",
    "|-----------------|--------|--------|\n",
    "| **ABX Duration** |        |        |\n",
    "| < 7 days        | 39     | 31     |\n",
    "| ≥ 7 days        | 51     | 53     |\n",
    "| **Age**         |        |        |\n",
    "| < 12 months     | 75     | 35     |\n",
    "| 12-24 months    | 34     | 38     |\n",
    "\n",
    "To run this notebook you need to create and activate the following conda environment:\n",
    "\n",
    "```\n",
    "conda create --name score_eval -c conda-forge -c defaults numpy pandas matplotlib seaborn scipy scikit-learn ipython ipykernel -y\n",
    "conda activate score_eval\n",
    "pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency, mannwhitneyu\n",
    "\n",
    "from src.utils_eval_score import (\n",
    "    _plot_score_after_nth_abx_exposure,\n",
    "    _select_samples_around_nth_abx_exposure,\n",
    "    get_scores_n_abx_info,\n",
    "    plot_trajectory,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({\"font.family\": \"DejaVu Sans\"})\n",
    "plt.style.use(\"tableau-colorblind10\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "# avg. number of days per month\n",
    "DAYS_PER_MONTH = 30.437"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER input: define the inferred model and linked datasets to evaluate here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT START\n",
    "# name of the model\n",
    "model_name = \"saved_models_microbial_novel_alpha_div2/id-55\"\n",
    "# which model version to evaluate: \"best\" or \"last\"\n",
    "point_to_evaluate = \"best\"\n",
    "\n",
    "# name of feature dataset used for model\n",
    "ft_name = \"ft_vat19_anomaly_v20240806_entero_genus\"\n",
    "# name of abx time-series used for model\n",
    "abx_ts_name = \"ts_vat19_abx_v20240806\"\n",
    "\n",
    "# limit evaluation to time range up to this many months (if None no limit is set\n",
    "# and all scores are evaluated)\n",
    "limit_months = 24.0\n",
    "\n",
    "# whether to group samples prior to abx exposure in analysis\n",
    "group_samples = True\n",
    "\n",
    "# ! which abx exposure to analyse in this notebook\n",
    "n = 1\n",
    "\n",
    "# ! how many samples prior and after abx exposure to consider\n",
    "min_samples = -3.0\n",
    "# 3.0 for n=1, 4.0 for n=2\n",
    "max_samples = 3.0  \n",
    "\n",
    "# whether to filter noabx score samples by having at least 1 obs prior to cutoff\n",
    "no_filter = True\n",
    "\n",
    "# whether to display diet info after 1st, 2nd, 3rd abx exposure plots\n",
    "display_diet_info = True\n",
    "\n",
    "# whether to have max. resolution of 0.5 months or not\n",
    "max_resolution = False\n",
    "\n",
    "# scaling factor options:\n",
    "scaling_factors_used = True\n",
    "\n",
    "# if scaling_factors_used is True, then the following options are required:\n",
    "# non-centered = \"nc_std\" or centered = \"std\"\n",
    "stddev_type = \"nc_std\"\n",
    "# moving average window size: 30 or 10\n",
    "moving_avg = 10\n",
    "# whether to include duplicates: \"--RD-True\" or \"\"\n",
    "duplicates = \"--RD-False\"\n",
    "# using lower bound of 1 for SFs: \"lower_bound-1\" or \"\"\n",
    "lower_bound = \"\"\n",
    "\n",
    "#### USER INPUT END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = f\"../data/{model_name}/anomaly_detection/\"\n",
    "\n",
    "res_n_group = f\"g{str(group_samples)[0]}_maxres{str(max_resolution)[0]}\"\n",
    "\n",
    "if scaling_factors_used:\n",
    "    print(\"Scaling factors used.\")\n",
    "    folder_name = f\"using-SF_{stddev_type}_z_scores--moving_avg-{moving_avg}-cummax{lower_bound}{duplicates}\"\n",
    "\n",
    "    scores_path = f\"{base_path}scores_{point_to_evaluate}_normal/{folder_name}/\"\n",
    "    evaluation_path = f\"{base_path}evaluation_{point_to_evaluate}_overall_{res_n_group}_{stddev_type}_ma{moving_avg}{duplicates.replace('-', '_').lower()}/\"\n",
    "else:\n",
    "    scores_path = f\"{base_path}scores_{point_to_evaluate}_normal/\"\n",
    "    evaluation_path = (\n",
    "        f\"{base_path}evaluation_{point_to_evaluate}_overall_{res_n_group}_no_scaling/\"\n",
    "    )\n",
    "if not os.path.exists(evaluation_path):\n",
    "    os.makedirs(evaluation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noabx_train, noabx_val, abx_scores_flat, abx_df, abx_age_at_all = get_scores_n_abx_info(\n",
    "    scores_path, ft_name, limit_months, abx_ts_name, no_filter=no_filter\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_events = pd.DataFrame()\n",
    "abx_events[\"host_id\"] = abx_scores_flat[\"host_id\"].unique()\n",
    "abx_events = pd.merge(abx_events, abx_df, on=\"host_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectories with large vs. no increase after abx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT & PREPARE SAMPLES\n",
    "score_col = f\"score_{n}\"\n",
    "\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "    abx_scores_flat,\n",
    "    abx_df,\n",
    "    n=n,\n",
    "    min_samples=min_samples,\n",
    "    max_samples=max_samples,\n",
    "    group_samples=group_samples,\n",
    "    score_var=score_col,\n",
    "    max_resolution=max_resolution,\n",
    ")\n",
    "\n",
    "scores_abx_nth_samples.drop(\n",
    "    columns=[\n",
    "        \"abx\",\n",
    "        \"score_0\",\n",
    "        \"div_alpha_observed_features\",\n",
    "        \"div_alpha_faith_pd\",\n",
    "        \"div_alpha_shannon\",\n",
    "        \"max_abx_w_microbiome\",\n",
    "        \"abx_max_count_ever\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# select only samples that have a -1 score\n",
    "hosts_w_prior_sample = scores_abx_nth_samples[\n",
    "    scores_abx_nth_samples[\"diff_age_nth_abx\"] == -1.0\n",
    "].host_id.unique()\n",
    "len(hosts_w_prior_sample)\n",
    "\n",
    "print(scores_abx_nth_samples.shape)\n",
    "scores_abx_nth_samples = scores_abx_nth_samples[\n",
    "    scores_abx_nth_samples.host_id.isin(hosts_w_prior_sample)\n",
    "]\n",
    "print(scores_abx_nth_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute relative score: max score in 3 or 4 months after abx exposure\n",
    "scores_abx_nth_samples = (\n",
    "    scores_abx_nth_samples.groupby(\"host_id\")\n",
    "    .apply(\n",
    "        lambda x: x.assign(\n",
    "            score_rel_change_1=x[score_col] / x[score_col].shift(1),\n",
    "            score_rel_change_2=x[score_col] / x[score_col].shift(2),\n",
    "            score_rel_change_3=x[score_col] / x[score_col].shift(3),\n",
    "            score_rel_change_4=x[score_col] / x[score_col].shift(4),\n",
    "        ),\n",
    "        include_groups=False,\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "scores_abx_nth_samples.drop(columns=\"level_1\", inplace=True)\n",
    "\n",
    "if n == 1:\n",
    "    scores_abx_nth_samples.drop(columns=\"score_rel_change_4\", inplace=True)\n",
    "\n",
    "# Identify all columns relevant to score_rel_change\n",
    "rel_change_cols = [\n",
    "    col for col in scores_abx_nth_samples.columns if col.startswith(\"score_rel_change_\")\n",
    "]\n",
    "# Select those columns, forward-fill each row, and pick the last non-NaN entry\n",
    "scores_abx_nth_samples[\"score_rel_change\"] = (\n",
    "    scores_abx_nth_samples[rel_change_cols]\n",
    "    .ffill(axis=1)  # fill forward along each row\n",
    "    .iloc[:, -1]  # take the rightmost (last) non-NaN value\n",
    ")\n",
    "df_max_rel_change = (\n",
    "    scores_abx_nth_samples.groupby(\"host_id\", as_index=False)[\"score_rel_change\"]\n",
    "    .max()\n",
    "    .rename(columns={\"score_rel_change\": \"max_score_rel_change\"})\n",
    ")\n",
    "df_max_rel_change.dropna(inplace=True)\n",
    "\n",
    "print(\n",
    "    f\"Number of unique infants with quantifiable rel score change: {df_max_rel_change.host_id.nunique()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_abx_nth_samples[\"months_since_last_prior_sample\"] = (\n",
    "    scores_abx_nth_samples[\"age_nth_abx\"] - scores_abx_nth_samples[\"month5_bin\"]\n",
    ")\n",
    "\n",
    "scores_abx_nth_samples[\n",
    "    [\n",
    "        \"host_id\",\n",
    "        \"diff_age_nth_abx\",\n",
    "        \"age_nth_abx\",\n",
    "        \"month5_bin\",\n",
    "        \"months_since_last_prior_sample\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_abx_nth_samples[\"gastroenteritis\"] = \"Others\"\n",
    "scores_abx_nth_samples.loc[\n",
    "    scores_abx_nth_samples[\"abx_reason\"] == \"Gastroenteritis\", \"gastroenteritis\"\n",
    "] = \"Gastroenteritis\"\n",
    "\n",
    "scores_abx_nth_samples[\"gastroenteritis\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get abx duration for these infants\n",
    "df_duration = scores_abx_nth_samples.groupby(\"host_id\", as_index=False)[\n",
    "    \"abx_any_last_dur_days\"\n",
    "].last()\n",
    "df_duration.dropna(inplace=True)\n",
    "\n",
    "df_rel_change = pd.merge(df_max_rel_change, df_duration, on=\"host_id\", how=\"left\")\n",
    "print(\n",
    "    f\"Number of unique infants with quantifiable rel score change + abx duration: {df_rel_change.host_id.nunique()}\"\n",
    ")\n",
    "\n",
    "# get all other characteristics in -1 bin before abx exposure\n",
    "characteristics_numeric = [\"month5_bin\", f\"score_{n}\", \"months_since_last_prior_sample\"]\n",
    "\n",
    "characteristics_cat = [\n",
    "    \"diet_milk\",\n",
    "    \"diet_weaning\",\n",
    "    \"delivery_mode\",\n",
    "    \"abx_reason\",\n",
    "    \"gastroenteritis\",\n",
    "    \"abx_type\",\n",
    "]\n",
    "\n",
    "cols_to_select = [\"host_id\"] + characteristics_numeric + characteristics_cat\n",
    "df_charc = scores_abx_nth_samples.loc[\n",
    "    scores_abx_nth_samples[\"diff_age_nth_abx\"] == -1.0, cols_to_select\n",
    "]\n",
    "\n",
    "df_rel_change_final = pd.merge(df_rel_change, df_charc, on=\"host_id\", how=\"left\")\n",
    "print(\n",
    "    f\"Number of unique infants with quantifiable rel score change + abx duration + chars: {df_rel_change_final.host_id.nunique()}\"\n",
    ")\n",
    "\n",
    "# transform categoricals to proper categoricals:\n",
    "for cat in characteristics_cat:\n",
    "    df_rel_change_final[cat] = df_rel_change_final[cat].astype(\"category\")\n",
    "\n",
    "df_rel_change_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE GROUPS\n",
    "# thresh = df_rel_change_final[\"max_score_rel_change\"].quantile(0.75)\n",
    "# print(thresh)\n",
    "thresh = 2.0\n",
    "\n",
    "rel_increase = df_rel_change_final.loc[\n",
    "    df_rel_change_final[\"max_score_rel_change\"] >= thresh\n",
    "]\n",
    "print(rel_increase.host_id.nunique())\n",
    "\n",
    "rel_no_increase = df_rel_change_final.loc[\n",
    "    df_rel_change_final[\"max_score_rel_change\"] < thresh\n",
    "]\n",
    "print(rel_no_increase.host_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics_numeric += [\"abx_any_last_dur_days\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe CHARACTERISTICS\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Aggregate results for each group\n",
    "for label, group in [\n",
    "    (\"increase\", rel_increase),\n",
    "    (\"no_increase\", rel_no_increase),\n",
    "]:\n",
    "    # nb infants\n",
    "    nb_infants = group.host_id.nunique()\n",
    "    results_df.loc[label, \"nb_infants\"] = nb_infants\n",
    "\n",
    "    # Summaries for numeric columns\n",
    "    for c in characteristics_numeric:\n",
    "        stats = group[c].describe()\n",
    "        mean_val = round(stats[\"mean\"], 2)\n",
    "        std_val = round(stats[\"std\"], 2)\n",
    "        results_df.loc[label, c] = f\"{mean_val} ± {std_val}\"\n",
    "\n",
    "    # Fractions for each category value\n",
    "    for cat in characteristics_cat:\n",
    "        cat_counts = group[cat].value_counts(dropna=False)\n",
    "        for val, cnt in cat_counts.items():\n",
    "            fraction = round(cnt / nb_infants, 2)\n",
    "            results_df.loc[label, f\"{cat}_{val}\"] = fraction\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTICAL TESTS for characteristics\n",
    "sign_numeric_df = pd.DataFrame()\n",
    "\n",
    "# Mann-Whitney U for numeric columns\n",
    "for c in characteristics_numeric:\n",
    "    inc_vals = rel_increase[c].dropna()\n",
    "    no_inc_vals = rel_no_increase[c].dropna()\n",
    "    stat, p_val = mannwhitneyu(inc_vals, no_inc_vals, alternative=\"two-sided\")\n",
    "    sign_numeric_df.loc[c, \"statistic\"] = round(stat, 4)\n",
    "    sign_numeric_df.loc[c, \"p-value\"] = p_val\n",
    "\n",
    "# Chi-square for categorical columns\n",
    "sign_cat_df = pd.DataFrame()\n",
    "for cat in characteristics_cat:\n",
    "    inc_c = rel_increase[cat].dropna().value_counts()\n",
    "    no_c = rel_no_increase[cat].dropna().value_counts()\n",
    "    contingency = pd.DataFrame([inc_c, no_c], index=[\"increase\", \"no_increase\"]).fillna(\n",
    "        0\n",
    "    )\n",
    "    chi2, p_val, dof, expected = chi2_contingency(contingency)\n",
    "    sign_cat_df.loc[cat, \"chi2_statistic\"] = round(chi2, 4)\n",
    "    sign_cat_df.loc[cat, \"p-value\"] = p_val\n",
    "\n",
    "print(\"\\nNumeric Significance Results:\")\n",
    "print(sign_numeric_df)\n",
    "print(\"\\nCategorical Significance Results:\")\n",
    "print(sign_cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# CREATE SUBPLOTS\n",
    "#   2 rows x 5 columns to accommodate 5 categorical variables (row 1)\n",
    "#   and 2 numeric variables (row 2, columns 0 & 1 only)\n",
    "# ----------------------------\n",
    "n_rows = len(characteristics_numeric) + len(characteristics_cat)\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=n_rows, ncols=1, figsize=(8, 20), dpi=600\n",
    ")  # , sharex=True)\n",
    "# fig.suptitle(\"Comparison of Characteristics for 'increase' vs. 'no_increase'\", fontsize=12, y=1.02)\n",
    "\n",
    "for idx, c in enumerate(characteristics_numeric):\n",
    "    increase_vals = rel_increase[c].dropna()\n",
    "    no_increase_vals = rel_no_increase[c].dropna()\n",
    "\n",
    "    axs[idx].boxplot(\n",
    "        [increase_vals, no_increase_vals], labels=[\"increase\", \"no_increase\"]\n",
    "    )\n",
    "    axs[idx].set_ylabel(c)\n",
    "\n",
    "# Stacked barplots for each categorical variable\n",
    "for idx_cat, cat in enumerate(characteristics_cat):\n",
    "    idx_cat_true = idx + idx_cat + 1\n",
    "    cat_fraction_cols = [col for col in results_df.columns if col.startswith(cat + \"_\")]\n",
    "    results_df[cat_fraction_cols].plot(\n",
    "        kind=\"bar\",\n",
    "        stacked=True,\n",
    "        ax=axs[idx_cat_true],\n",
    "    )\n",
    "    axs[idx_cat_true].set_ylabel(\n",
    "        f\"{cat} fractions\",\n",
    "    )\n",
    "    # Remove the prefix for cleaner legend labels\n",
    "    handles, labels = axs[idx_cat_true].get_legend_handles_labels()\n",
    "    new_labels = [label.replace(cat + \"_\", \"\") for label in labels]\n",
    "    axs[idx_cat_true].legend(\n",
    "        handles, new_labels, title=cat, bbox_to_anchor=(1.05, 1), loc=\"upper left\"\n",
    "    )\n",
    "\n",
    "# Remove x-axis ticks and labels from all subplots except the last one\n",
    "for ax in axs[:-1]:\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticklabels([])\n",
    "for tick in axs[-1].get_xticklabels():\n",
    "    tick.set_rotation(0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_increase_scores = scores_abx_nth_samples.loc[\n",
    "    scores_abx_nth_samples[\"host_id\"].isin(rel_increase[\"host_id\"])\n",
    "]\n",
    "_plot_score_after_nth_abx_exposure(\n",
    "    group_increase_scores,\n",
    "    x_axis=\"diff_age_nth_abx\",\n",
    "    y_axis=score_col,\n",
    "    n=n,\n",
    "    path_to_save=None,\n",
    "    flag=score_col,\n",
    "    tag=\": relative score increase\",\n",
    "    min_samples=min_samples,\n",
    "    max_samples=max_samples,\n",
    "    max_resolution=max_resolution,\n",
    "    grouped_samples=group_samples,\n",
    ")\n",
    "\n",
    "group_no_increase_scores = scores_abx_nth_samples.loc[\n",
    "    scores_abx_nth_samples[\"host_id\"].isin(rel_no_increase[\"host_id\"])\n",
    "]\n",
    "_plot_score_after_nth_abx_exposure(\n",
    "    group_no_increase_scores,\n",
    "    x_axis=\"diff_age_nth_abx\",\n",
    "    y_axis=score_col,\n",
    "    n=n,\n",
    "    path_to_save=None,\n",
    "    flag=score_col,\n",
    "    tag=\": relative score no increase\",\n",
    "    min_samples=min_samples,\n",
    "    max_samples=max_samples,\n",
    "    max_resolution=max_resolution,\n",
    "    grouped_samples=group_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot individual trajectories for infants with increased scores prior to abx exposure:\n",
    "\n",
    "infants_w_no_increase = rel_no_increase[\"host_id\"].unique().tolist()\n",
    "\n",
    "for infant in infants_w_no_increase:\n",
    "    plot_trajectory(\n",
    "        abx_scores_flat,\n",
    "        abx_events,\n",
    "        infant,\n",
    "        [f\"score_{n}\"],\n",
    "        path_to_output=None,\n",
    "        flag=f\"score_{n}\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "score_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
