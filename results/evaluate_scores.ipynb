{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to evaluate inferred microbial anomaly scores\n",
    "\n",
    "To run this notebook you need to create and activate the following conda environment:\n",
    "\n",
    "```\n",
    "conda create --name score_eval numpy pandas matplotlib seaborn scipy ipython ipykernel -y\n",
    "conda activate score_eval\n",
    "pip install -e .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils_eval_score import (\n",
    "    _get_all_scores,\n",
    "    _transform_scores,\n",
    "    _plot_score_over_age, \n",
    "    _get_abx_info,\n",
    "    _select_samples_around_nth_abx_exposure,\n",
    "    _plot_score_after_nth_abx_exposure,\n",
    "    display_scatterplot_w_scores,\n",
    "    plot_trajectory\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# avg. number of days per month\n",
    "DAYS_PER_MONTH = 30.437"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER input: define the inferred model and linked datasets to evaluate here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT START\n",
    "# name of the model\n",
    "model_name = \"saved_models_microbial_novel_alpha_div/id-2\"\n",
    "# which model version to evaluate: \"best\" or \"last\"\n",
    "point_to_evaluate = \"best\"\n",
    "\n",
    "# name of feature dataset used for model\n",
    "ft_name = \"ft_vat19_anomaly_v20240806_entero_family\"\n",
    "# name of abx time-series used for model\n",
    "abx_ts_name = \"ts_vat19_abx_v20240806\"\n",
    "\n",
    "# whether to group samples prior to abx exposure in analysis (increases\n",
    "# statistical power)\n",
    "group_samples = True\n",
    "\n",
    "# how many samples prior and after abx exposure to consider\n",
    "min_samples = -3.0\n",
    "max_samples = 12.0\n",
    "#### USER INPUT END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_path = f\"../data/{model_name}/anomaly_detection/scores_{point_to_evaluate}/\"\n",
    "evaluation_path = f\"../data/{model_name}/anomaly_detection/evaluation_{point_to_evaluate}/\"\n",
    "\n",
    "if not os.path.exists(evaluation_path):\n",
    "    os.makedirs(evaluation_path)\n",
    "\n",
    "split = \"both\"\n",
    "\n",
    "# get train\n",
    "scores_train = _get_all_scores(scores_path, \"train\")\n",
    "\n",
    "# get val\n",
    "scores_val = _get_all_scores(scores_path, \"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get noabx samples per split\n",
    "noabx_train = scores_train[~scores_train[\"abx\"]].copy()\n",
    "noabx_val = scores_val[~scores_val[\"abx\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all abx scores into one group: train + val\n",
    "abx_scores_flat = scores_train[scores_train[\"abx\"]].copy()\n",
    "abx_scores_flat_val = scores_val[scores_val[\"abx\"]].copy()\n",
    "\n",
    "abx_scores_flat = pd.concat([abx_scores_flat, abx_scores_flat_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add metadata matching samples over time from ft\n",
    "ft_df = pd.read_csv(f\"../data/original_data/{ft_name}.tsv\", sep=\"\\t\", index_col=0)\n",
    "ft_df[\"age_days\"] = ft_df[\"age_days\"].astype(int)\n",
    "ft_df.rename(columns={\"age_days\": \"day\"}, inplace=True)\n",
    "\n",
    "cols_to_evaluate = [\"abx_any_cumcount\", \"abx_max_count_ever\", \"abx_any_last_t_dmonths\", \"abx_any_last_dur_days\", \"geo_location_name\"]\n",
    "ft_df = ft_df[[\"day\", \"host_id\"] + cols_to_evaluate].copy()\n",
    "ft_df = ft_df.assign(\n",
    "    max_abx_w_microbiome=lambda df: df.groupby(\"host_id\")[\"abx_any_cumcount\"].transform(\n",
    "        \"max\"\n",
    "    ),\n",
    ")\n",
    "# add additional information to inferred scores\n",
    "print(abx_scores_flat.shape)\n",
    "abx_scores_flat = abx_scores_flat.merge(ft_df, on=[\"host_id\", \"day\"], how=\"left\")\n",
    "print(abx_scores_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select correct scores:\n",
    "# for scores prior to any abx & after 1st abx exposures: -> scores_0_1\n",
    "# for scores after 2nd abx exposure: -> scores_2\n",
    "# for scores after 3rd abx exposure: -> scores_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select correct scores:\n",
    "abx_scores_flat[\"score\"] = np.nan\n",
    "# for scores prior to any abx & after 1st abx exposures: -> scores_0_1\n",
    "abx_prior_n_1st = (abx_scores_flat[\"abx_any_cumcount\"] <= 1)\n",
    "abx_scores_flat.loc[abx_prior_n_1st, \"score\"] = abx_scores_flat[\"score_0_1\"]\n",
    "\n",
    "abx_2nd = (abx_scores_flat[\"abx_any_cumcount\"] == 2)\n",
    "abx_scores_flat.loc[abx_2nd, \"score\"] = abx_scores_flat[\"score_2\"]\n",
    "\n",
    "abx_3nd = (abx_scores_flat[\"abx_any_cumcount\"] == 3)\n",
    "abx_scores_flat.loc[abx_3nd, \"score\"] = abx_scores_flat[\"score_3\"]\n",
    "\n",
    "# remove former score_ columns\n",
    "abx_scores_flat = abx_scores_flat.drop(\n",
    "    columns=[\n",
    "        \"score_0_1\",\n",
    "        \"score_2\",\n",
    "        \"score_3\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# keep only rows that have a score\n",
    "abx_scores_flat = abx_scores_flat[abx_scores_flat.score.notnull()].copy()\n",
    "abx_scores_flat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after abx exposure 1st, 2nd and 3rd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_abx_ts = f\"../data/original_data/{abx_ts_name}.tsv\"\n",
    "abx_df = _get_abx_info(path_to_abx_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get samples around n-th abx exposure\n",
    "for n in [1, 2, 3]:\n",
    "    scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "        abx_scores_flat, abx_df, n=n, \n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        group_samples=group_samples\n",
    "    )\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=\"score\",\n",
    "        n=n,\n",
    "        path_to_save=evaluation_path,\n",
    "        flag=split,\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 1st abx: split by duration: < 7 days vs. >= 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "        abx_scores_flat, abx_df, n=n, min_samples=min_samples, max_samples=max_samples,group_samples=group_samples)\n",
    "\n",
    "# bin duration into short, mid and long duration\n",
    "scores_abx_nth_samples[\"abx_any_last_dur_days\"].hist(bins=10)\n",
    "\n",
    "bins = [-float('inf'), 6, float('inf')]\n",
    "dur_labels = ['< 6 days', '>= 6 days']\n",
    "scores_abx_nth_samples['abx_duration_category'] = pd.cut(scores_abx_nth_samples['abx_any_last_dur_days'], bins=bins, labels=dur_labels, right=False)\n",
    "\n",
    "scores_abx_nth_samples['abx_duration_category'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for dur in dur_labels:\n",
    "    print(dur)\n",
    "    # evaluation_path_bin = f\"{evaluation_path}duration_bins{i}/\"\n",
    "    host_w_dur = scores_abx_nth_samples.loc[scores_abx_nth_samples['abx_duration_category'] == dur, \"host_id\"].unique().tolist()\n",
    "    scores_abx_nth_samples_dur = scores_abx_nth_samples.loc[scores_abx_nth_samples['host_id'].isin(host_w_dur)].copy()\n",
    "\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_dur,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=\"score\",\n",
    "        n=n,\n",
    "        path_to_save=None,\n",
    "        flag=split,\n",
    "        tag = f\"duration: {dur}\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 1st abx: split by time of life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "        abx_scores_flat, abx_df, n=n, min_samples=min_samples, max_samples=max_samples, group_samples=group_samples)\n",
    "\n",
    "# bin duration into short, mid and long duration\n",
    "scores_abx_nth_samples[\"age_nth_abx\"].hist(bins=24)\n",
    "\n",
    "bins_age = [-float('inf'), 12, float('inf')]\n",
    "# <6: pre weaning\n",
    "age_labels = ['< 12 months', '>= 12 months']\n",
    "scores_abx_nth_samples['age_nth_abx_category'] = pd.cut(scores_abx_nth_samples['age_nth_abx'], bins=bins_age, labels=age_labels, right=False)\n",
    "\n",
    "scores_abx_nth_samples['age_nth_abx_category'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for a in age_labels:\n",
    "    print(a)\n",
    "    # evaluation_path_bin = f\"{evaluation_path}age_bins{i}/\"\n",
    "    \n",
    "    # age at time of abx exposure should match a\n",
    "    scores_abx_nth_samples_age = scores_abx_nth_samples.loc[scores_abx_nth_samples['age_nth_abx_category']==a].copy()\n",
    "\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_age,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=\"score\",\n",
    "        n=n,\n",
    "        path_to_save=None,\n",
    "        flag=split,\n",
    "        tag = f\"age: {a}\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 1st abx: split by type of abx (top 4 distinct categories prescribed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "        abx_scores_flat, abx_df, n=n, min_samples=min_samples, max_samples=max_samples, group_samples=group_samples)\n",
    "\n",
    "scores_abx_nth_samples[\"abx_type\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select types to look for\n",
    "abx_types = [\"Penicillin\", \"Cephalosporine\", \"Cotrimoxazole\", \"Macrolide\"]\n",
    "abx_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for abx in abx_types:\n",
    "    print(abx)\n",
    "    abx_str = abx.lower().replace(\" \", \"_\").replace(\",\", \"_\")\n",
    "    # evaluation_path_abx = f\"{evaluation_path}abx_type_{abx_str}/\"\n",
    "\n",
    "    # age at time of abx exposure should match a\n",
    "    scores_abx_nth_samples_abx = scores_abx_nth_samples.loc[scores_abx_nth_samples['abx_type'].str.contains(abx)].copy()\n",
    "\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_abx,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=\"score\",\n",
    "        n=n,\n",
    "        path_to_save=None,\n",
    "        flag=split,\n",
    "        tag = f\"Abx type: {abx}\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score after 1st abx: split by type of abx reason (top 4 distinct categories prescribed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "scores_abx_nth_samples = _select_samples_around_nth_abx_exposure(\n",
    "        abx_scores_flat, abx_df, n=n, min_samples=min_samples, max_samples=max_samples, group_samples=group_samples)\n",
    "print(scores_abx_nth_samples[\"abx_reason\"].value_counts(dropna=False))\n",
    "reasons = scores_abx_nth_samples[\"abx_reason\"].value_counts(dropna=False).iloc[:4].index.tolist()\n",
    "reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in reasons:\n",
    "    print(r)\n",
    "    r_str = r.lower().replace(\" \", \"_\").replace(\",\", \"_\")\n",
    "    # evaluation_path_r = f\"{evaluation_path}abx_reason_{r_str}/\"\n",
    "\n",
    "    # age at time of abx exposure should match a\n",
    "    scores_abx_nth_samples_r = scores_abx_nth_samples.loc[scores_abx_nth_samples['abx_reason']==r].copy()\n",
    "\n",
    "    _plot_score_after_nth_abx_exposure(\n",
    "        scores_abx_nth_samples_r,\n",
    "        x_axis=\"diff_age_nth_abx\",\n",
    "        y_axis=\"score\",\n",
    "        n=n,\n",
    "        path_to_save=None,\n",
    "        flag=split,\n",
    "        tag = f\"Abx reason: {r}\",\n",
    "        min_samples=min_samples,\n",
    "        max_samples=max_samples,\n",
    "        grouped_samples=group_samples\n",
    "    )\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score over age range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_splits_n_scores = {\n",
    "    \"train_noabx\": noabx_train,\n",
    "    \"val_noabx\": noabx_val,\n",
    "    \"abx\": abx_scores_flat\n",
    "}\n",
    "\n",
    "for name, scores in dic_splits_n_scores.items():\n",
    "    _plot_score_over_age(scores, name, evaluation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score overall - scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort both abx dataframes by increasing abx exposure in same way\n",
    "abx_scores_flat.sort_values(\n",
    "    [\n",
    "        \"abx_max_count_ever\",\n",
    "        \"max_abx_w_microbiome\",\n",
    "        \"host_id\",\n",
    "        \"day\",\n",
    "    ],\n",
    "    ascending=[True, True, True, True],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# sort abx_df accordingly\n",
    "# sort abx_df in same order and remove samples that don't exist in md_df\n",
    "abx_events = pd.DataFrame()\n",
    "abx_events[\"host_id\"] = abx_scores_flat[\"host_id\"].unique()\n",
    "abx_events = pd.merge(abx_events, abx_df, on=\"host_id\", how=\"left\")\n",
    "\n",
    "assert abx_events.host_id.unique().tolist() == abx_scores_flat.host_id.unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_splits = {\n",
    "    \"train_noabx\": [noabx_train, None],\n",
    "    \"val_noabx\": [noabx_val, None],\n",
    "    \"abx\": [abx_scores_flat, abx_events]\n",
    "}\n",
    "\n",
    "display_scatterplot_w_scores(dic_splits, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual trajectories: score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(abx_scores_flat,abx_events,  \"E004628\", \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(abx_scores_flat, abx_events,  \"E021822\", \"score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### noabx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(noabx_train, None,  \"E035134\", \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(noabx_train, None,  \"E022497\", \"score\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "njode_scores",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
