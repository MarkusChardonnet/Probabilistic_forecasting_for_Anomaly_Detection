{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook exploring distribution of score_0 vs. score_2\n",
    "\n",
    "To run this notebook you need to create and activate the following conda environment:\n",
    "\n",
    "```\n",
    "conda create --name score_eval -c conda-forge -c defaults numpy pandas matplotlib seaborn scipy scikit-learn ipython ipykernel -y\n",
    "conda activate score_eval\n",
    "pip install -e .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils_eval_score import (\n",
    "    display_scatterplot_w_scores,\n",
    "    get_scores_n_abx_info,\n",
    ")\n",
    "from src.utils_prediction import plot_distribution\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USER input: define the inferred model and linked datasets to evaluate here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT START\n",
    "# name of the model\n",
    "model_name = \"saved_models_microbial_novel_alpha_div2/id-55\"\n",
    "# which model version to evaluate: \"best\" or \"last\"\n",
    "point_to_evaluate = \"best\"\n",
    "\n",
    "# name of feature dataset used for model\n",
    "ft_name = \"ft_vat19_anomaly_v20240806_entero_genus\"\n",
    "# path to abx time-series file\n",
    "path_to_abx_data = \"../data/original_data/\"\n",
    "# name of abx time-series used for model\n",
    "abx_ts_name = \"ts_vat19_abx_v20240806\"\n",
    "\n",
    "# limit evaluation to time range up to this many months (if None no limit is set\n",
    "# and all scores are evaluated)\n",
    "limit_months = 24.0\n",
    "\n",
    "# scaling factor options:\n",
    "scaling_factors_used = True\n",
    "\n",
    "# if scaling_factors_used is True, then the following options are required:\n",
    "# non-centered = \"nc_std\" or centered = \"std\"\n",
    "stddev_type = \"nc_std\"\n",
    "# moving average window size: 30 or 10\n",
    "moving_avg = 10\n",
    "# whether to include duplicates: \"--RD-True\" or \"\"\n",
    "duplicates = \"\"\n",
    "\n",
    "#### USER INPUT END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = f\"../data/{model_name}/anomaly_detection/\"\n",
    "\n",
    "if scaling_factors_used:\n",
    "    print(\"Scaling factors used.\")\n",
    "    folder_name = f\"using-SF_{stddev_type}_z_scores--moving_avg-{moving_avg}-cummax-lower_bound-1{duplicates}\"\n",
    "\n",
    "    scores_path = f\"{base_path}scores_{point_to_evaluate}_normal/{folder_name}/\"\n",
    "    evaluation_path = f\"{base_path}evaluation_{point_to_evaluate}_unsupervised_pred_{stddev_type}_ma{moving_avg}{duplicates.replace(\"-\", \"_\").lower()}/\"\n",
    "else:\n",
    "    scores_path = f\"{base_path}scores_{point_to_evaluate}_normal/\"\n",
    "    evaluation_path = f\"{base_path}evaluation_{point_to_evaluate}_unsupervised_pred/\"\n",
    "\n",
    "if not os.path.exists(evaluation_path):\n",
    "    os.makedirs(evaluation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scores\n",
    "noabx_train, noabx_val, abx_scores_flat, abx_df, abx_age_at_all = get_scores_n_abx_info(\n",
    "    scores_path, ft_name, limit_months, abx_ts_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration: Score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noabx_train[[\"score_0\", \"score_1\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx_scores_flat[[\"score_0\", \"score_1\", \"score_2\", \"score_3\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot score_0 vs score_1 for abx cohort\n",
    "plot_distribution(\n",
    "    columns=[\"score_0\", \"score_1\"],\n",
    "    dataframes={\"abx_scores_flat\": abx_scores_flat},\n",
    "    figsize=(4, 5),\n",
    "    kde=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot score_0 for abx vs. noabx train cohort\n",
    "plot_distribution(\n",
    "    columns=\"score_0\",\n",
    "    dataframes={\n",
    "        \"abx_scores_flat\": abx_scores_flat,\n",
    "        \"noabx_train\": noabx_train,\n",
    "        \"noabx_val\": noabx_val,\n",
    "    },\n",
    "    figsize=(10, 6),\n",
    "    kde=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort both abx dataframes by increasing abx exposure in same way\n",
    "abx_scores_flat.sort_values(\n",
    "    [\n",
    "        \"abx_max_count_ever\",\n",
    "        \"max_abx_w_microbiome\",\n",
    "        \"host_id\",\n",
    "        \"day\",\n",
    "    ],\n",
    "    ascending=[True, True, True, True],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# sort abx_df accordingly\n",
    "# sort abx_df in same order and remove samples that don't exist in md_df\n",
    "abx_events = pd.DataFrame()\n",
    "abx_events[\"host_id\"] = abx_scores_flat[\"host_id\"].unique()\n",
    "abx_events = pd.merge(abx_events, abx_df, on=\"host_id\", how=\"left\")\n",
    "assert abx_events.host_id.unique().tolist() == abx_scores_flat.host_id.unique().tolist()\n",
    "\n",
    "# display scatter\n",
    "dic_splits = {\n",
    "    \"train_noabx\": [\"score_0\", noabx_train, None],\n",
    "    \"val_noabx\": [\"score_0\", noabx_val, None],\n",
    "    \"abx\": [\"score_0\", abx_scores_flat, abx_events],\n",
    "}\n",
    "\n",
    "display_scatterplot_w_scores(\n",
    "    dic_splits, False, path_to_output=evaluation_path, flag=\"noabx_vs_abx\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "score_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
